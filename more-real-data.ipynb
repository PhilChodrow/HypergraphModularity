{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"jl/inference.jl\")\n",
    "include(\"jl/objectives.jl\")\n",
    "using Printf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "function read_hypergraph_data(dataname::String, maxsize::Int64=25)\n",
    "    labels = Int64[]\n",
    "    open(\"data/$dataname/node-labels-$dataname.txt\") do f\n",
    "        for line in eachline(f)\n",
    "            push!(labels, parse(Int64, line))\n",
    "        end\n",
    "    end\n",
    "    n = length(labels)\n",
    "\n",
    "    E = Dict{Integer, Dict}()\n",
    "    open(\"data/$dataname/hyperedges-$dataname.txt\") do f\n",
    "        for line in eachline(f)\n",
    "            edge = [parse(Int64, v) for v in split(line, ',')]\n",
    "            sort!(edge)\n",
    "            if length(edge) > maxsize; continue; end\n",
    "            sz = length(edge)\n",
    "            if !haskey(E, sz)\n",
    "                E[sz] = Dict{}()\n",
    "            end\n",
    "            E[sz][edge] = 1\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    D = zeros(Int64, n)\n",
    "    for (sz, edges) in E\n",
    "        for (e, _) in edges\n",
    "            D[e] .+= 1\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    N = 1:n\n",
    "    \n",
    "    return hypergraph(N, E, D), labels\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "estimate_all (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A bunch of move-based aggregation functions,\n",
    "# all stratified by hyperedge size\n",
    "\n",
    "identity(p::Vector{Int64}) = p\n",
    "\n",
    "function discount_cut(p::Vector{Int64}, α=1.0)\n",
    "    discount = sum(p .^ α) - maximum(p) ^ α\n",
    "    return (sum(p), discount)\n",
    "end\n",
    "\n",
    "function sum_of_ext_degs(p::Vector{Int64})\n",
    "    soed = length(p) - 1\n",
    "    return (sum(p), soed)\n",
    "end\n",
    "\n",
    "function all_or_nothing(p::Vector{Int64})\n",
    "    is_aon = length(p) == 1\n",
    "    return (sum(p), is_aon)\n",
    "end\n",
    "\n",
    "function rainbow(p::Vector{Int64})\n",
    "    is_rainbow = length(p) == sum(p) && length(p) > 1\n",
    "    return (sum(p), is_rainbow)\n",
    "end\n",
    "\n",
    "\n",
    "function estimate_all(H, labels)\n",
    "    aggs = [identity, discount_cut, sum_of_ext_degs, \n",
    "            all_or_nothing, rainbow]\n",
    "    return [estimateΩEmpirically(H, labels; min_val=0, \n",
    "                                 aggregator=agg) for agg in aggs]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "show_estimates (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function show_estimates(H, labels, maxk)\n",
    "    Ω̂s = estimate_all(H, labels)\n",
    "    for k = 1:maxk\n",
    "        for p in partitions(k)\n",
    "            estimates = [Ω̂(p; α=1, mode=\"partition\") for Ω̂ in Ω̂s]\n",
    "            strs = join([@sprintf(\"%.3e\", est) for est in estimates], \", \")\n",
    "            println(\"$p\\n\\t$strs\\n\")\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comparisons (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function comparisons(H, labels, krange)\n",
    "    @time Ω̂ = estimateΩEmpirically(H, labels; min_val=0,\n",
    "                                    aggregator=discount_cut)\n",
    "    for k in krange\n",
    "        p1 = [k]\n",
    "        p2 = [k - 1, 1]\n",
    "        p3 = [ceil(Int64, k / 2), floor(Int64, k / 2)]\n",
    "        e1 = Ω̂(p1; α=1, mode=\"partition\")\n",
    "        e2 = Ω̂(p2; α=1, mode=\"partition\")\n",
    "        e3 = Ω̂(p3; α=1, mode=\"partition\")    \n",
    "        r1 = round(e1 / e2, digits=4)\n",
    "        r2 = round(e1 / e3, digits=4)\n",
    "        println(\"\\t $p1 / $p2 $r1   $p1 / $p3 $r2\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contact-primary-school...\n",
      "  0.032847 seconds (242.09 k allocations: 20.447 MiB)\n",
      "\t [2] / [1, 1] 1.6772   [2] / [1, 1] 1.6772\n",
      "\t [3] / [2, 1] 13.3441   [3] / [2, 1] 13.3441\n",
      "\t [4] / [3, 1] 23.2015   [4] / [2, 2] 87.1206\n",
      "walmart-trips...\n",
      "  1.247617 seconds (2.54 M allocations: 751.053 MiB, 20.34% gc time)\n",
      "\t [2] / [1, 1] 2.7346   [2] / [1, 1] 2.7346\n",
      "\t [3] / [2, 1] 2.7092   [3] / [2, 1] 2.7092\n",
      "\t [4] / [3, 1] 3.6565   [4] / [2, 2] 4.9379\n",
      "\t [5] / [4, 1] 4.6371   [5] / [3, 2] 6.1936\n",
      "\t [6] / [5, 1] 5.456   [6] / [3, 3] 10.179\n",
      "\t [7] / [6, 1] 7.8185   [7] / [4, 3] 17.587\n",
      "\t [8] / [7, 1] 8.1443   [8] / [4, 4] 28.8033\n",
      "\t [9] / [8, 1] 8.6439   [9] / [5, 4] 52.4397\n",
      "\t [10] / [9, 1] 11.0399   [10] / [5, 5] 103.4761\n",
      "TrivagoClickout...\n",
      "  2.635525 seconds (5.66 M allocations: 995.895 MiB, 36.10% gc time)\n",
      "\t [2] / [1, 1] NaN   [2] / [1, 1] NaN\n",
      "\t [3] / [2, 1] 1005.4393   [3] / [2, 1] 1005.4393\n",
      "\t [4] / [3, 1] 1178.5841   [4] / [2, 2] 23684.2647\n",
      "\t [5] / [4, 1] 1656.1087   [5] / [3, 2] 20785.7698\n",
      "\t [6] / [5, 1] 1551.9434   [6] / [3, 3] 345824.0462\n",
      "\t [7] / [6, 1] 1971.9878   [7] / [4, 3] 427800.2384\n",
      "\t [8] / [7, 1] 2351.6569   [8] / [4, 4] 7.2027577166e6\n",
      "\t [9] / [8, 1] 2253.443   [9] / [5, 4] 8.1527478669e6\n",
      "\t [10] / [9, 1] 3476.0597   [10] / [5, 5] 1.209965532899e8\n",
      "\t [11] / [10, 1] 4109.8377   [11] / [6, 5] 1.197448934955e8\n",
      "\t [12] / [11, 1] 4515.6672   [12] / [6, 6] 2.3021092202958e9\n",
      "congress-bills...\n",
      "  1.141582 seconds (2.70 M allocations: 772.754 MiB, 24.67% gc time)\n",
      "\t [2] / [1, 1] 1.4273   [2] / [1, 1] 1.4273\n",
      "\t [3] / [2, 1] 2.1327   [3] / [2, 1] 2.1327\n",
      "\t [4] / [3, 1] 3.1247   [4] / [2, 2] 3.0957\n",
      "\t [5] / [4, 1] 3.8465   [5] / [3, 2] 5.5969\n",
      "\t [6] / [5, 1] 4.6607   [6] / [3, 3] 8.8925\n",
      "\t [7] / [6, 1] 5.7288   [7] / [4, 3] 15.142\n",
      "\t [8] / [7, 1] 6.1799   [8] / [4, 4] 24.1219\n",
      "\t [9] / [8, 1] 6.8549   [9] / [5, 4] 37.8946\n",
      "\t [10] / [9, 1] 7.2146   [10] / [5, 5] 60.9311\n",
      "\t [11] / [10, 1] 9.0604   [11] / [6, 5] 105.6267\n",
      "\t [12] / [11, 1] 10.3664   [12] / [6, 6] 172.0001\n"
     ]
    }
   ],
   "source": [
    "for (dataset, krange) in [(\"contact-primary-school\", 2:4), \n",
    "                          (\"walmart-trips\", 2:10),\n",
    "                          (\"TrivagoClickout\", 2:12), \n",
    "                          (\"congress-bills\", 2:12)]\n",
    "    println(\"$dataset...\")\n",
    "    H, labels = read_hypergraph_data(dataset)\n",
    "    comparisons(H, labels, krange)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contact-primary-school\n",
      "   Identity                   L = -87116.4\n",
      "   Discount Cut               L = -87537.3\n",
      "   Sum of Exterior Degrees    L = -87124.0\n",
      "   Rainbow                    L = -104843.8\n",
      "   All or Nothing             L = -100816.5\n",
      "walmart-trips\n",
      "   Identity                   L = -1.7457772e6\n",
      "   Discount Cut               L = -1.7532442e6\n",
      "   Sum of Exterior Degrees    L = -1.7462504e6\n",
      "   Rainbow                    L = -1.7772907e6\n",
      "   All or Nothing             "
     ]
    }
   ],
   "source": [
    "aggregators = Dict(\n",
    "    \"Identity\"                => identity,\n",
    "    \"Discount Cut\"            => discount_cut,\n",
    "    \"Sum of Exterior Degrees\" => sum_of_ext_degs,\n",
    "    \"All or Nothing\"          => all_or_nothing,\n",
    "    \"Rainbow\"                 => rainbow\n",
    "    )\n",
    "\n",
    "function likelihoods(dataset)\n",
    "    \n",
    "    H, labels = read_hypergraph_data(dataset, 10)\n",
    "    for key ∈ keys(aggregators)\n",
    "        Ω̂ = estimateΩEmpirically(H, labels; min_val=1e-30,\n",
    "                                    aggregator=aggregators[key])\n",
    "\n",
    "        ll = sum(L(H, labels, Ω̂; α = 0, bigInt=true))\n",
    "        ll = round(Float64(ll, RoundDown),digits=1)\n",
    "        \n",
    "        println(rpad(\"   $key \", 30, \" \"), \"L = $ll\")\n",
    "    end\n",
    "end\n",
    "\n",
    "# for dataset ∈ [\"walmart-trips\"]\n",
    "for dataset ∈ [\"contact-primary-school\", \"walmart-trips\", \"TrivagoClickout\", \"congress-bills\"]\n",
    "    println(dataset)\n",
    "    likelihoods(dataset)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things are interesting about these results. First, the `Identity` aggregator always achieves the highest likelihood; this is expected since it contains the maximal number of parameters. The other aggregators vary in their relationship to the data. While `Rainbow` appears never to be competitive, the `Sum of Exterior Degrees` often performs nearly as well as the `Identity`. It is possible that the `Sum of Exterior Degrees` implicitly contains a large number of parameters, which would explain this behavior. One interesting approach would be to try to punish complexity associated with having many parameters -- an information criterion or explicit Bayesian prior would both be ways to do this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have restricted the data to edges of size 8 and below in this case. \n",
    "We get somewhat odd results on Trivago when using larger hyperedges (e.g. up to size 15). I think this is because there are several partitions \n"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.4.2",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
