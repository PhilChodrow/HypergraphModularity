{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning $\\hat{\\Omega}$\n",
    "\n",
    "In this notebook, we're going to demonstrate parameter inference for $\\Omega$, under the assumption that $\\Omega$ depends only on subgroup sizes within each edge. We consider a scenario in which we already know or have a guess about $Z$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using StatsBase\n",
    "using Combinatorics\n",
    "using Plots\n",
    "\n",
    "include(\"jl/omega.jl\")\n",
    "include(\"jl/HSBM.jl\")\n",
    "include(\"jl/inference.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing we'll do is define a set of parameters, including group memberships $Z$, degree parameters $\\vartheta$, and the connection function $\\Omega$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "n = 40\n",
    "Z = rand(1:5, n)\n",
    "ϑ = dropdims(ones(1,n) + rand(1,n), dims = 1)\n",
    "\n",
    "# defining group intensity function Ω\n",
    "μ = mean(ϑ)\n",
    "fk = k->(2*μ*k)^(-k)\n",
    "fp = harmonicMean\n",
    "Ω = z->groupSizePartition(z, fp, fk); # depends only on the size of the hyperedge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll sample from the HSBM with these parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hypergraph\n",
       "  E: Dict{Integer,Dict}\n",
       "  D: Dict{Integer,Integer}\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample from the HSBM with these parameters, restricting to hyperedges of size no more than kmax\n",
    "kmax = 4\n",
    "H = sampleSBM(Z, ϑ, Ω; kmax=kmax, kmin = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll use the function `estimateΩ` from `jl/inference.jl` to obtain an estimate $\\hat{\\Omega}$ of $\\Omega$ from the realized data. We'll also \"infer\" $\\vartheta$ from the data, although this is a trivial one-liner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ω̂ = estimateΩ(H, Z)\n",
    "function Ω̂(z)\n",
    "    p = -sort(-collect(values(countmap(vec(z)))))\n",
    "    get(ω̂,p,0)\n",
    "end\n",
    "\n",
    "# technically, this counts as \"inferring\" ϑ under our normalization scheme. This is just the degree sequence. \n",
    "ϑ̂ = 1.0*[H.D[i] for i in 1:length(H.D)];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can sample from the HSBM with the inferred parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_ = sampleSBM(Z, ϑ̂, Ω̂; kmax=kmax, kmin = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, because of the identifiability issues between $\\Omega$ and $\\vartheta$, we shouldn't expect that $\\hat{\\Omega}$ is close to $\\Omega$ or that $\\hat{\\vartheta}$ is close to $\\vartheta$. However, we can reasonably expect that the associated distributions over hypergraphs are reasonably similar. We can illustrate that heuristically by comparing the degree and dimension sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d  = [H.D[i] for i in 1:length(H.D)]\n",
    "d_ = [H_.D[i] for i in 1:length(H_.D)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot([0, maximum(d_)], [0, maximum(d_)], label= \"x = y\")\n",
    "plot!(d, d_, seriestype = :scatter,label=\"\", title = \"Comparison of Degree Sequences\", legend=:bottomright)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K  = [length(H.E[k]) for k in 1:maximum(keys(H.E))]\n",
    "K_ = [length(H_.E[k]) for k in 1:maximum(keys(H_.E))]\n",
    "\n",
    "plot([0, maximum(K_)], [0, maximum(K_)], label= \"x = y\")\n",
    "plot!(K, K_, seriestype = :scatter,label=\"\", title = \"Comparison of Dimension Sequences\", legend=:bottomright)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is reasonable qualitative evidence that we are able to correctly learn $\\Omega$ from data in this restricted case. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
