{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using NLopt\n",
    "using Optim\n",
    "using StatsBase\n",
    "using Combinatorics\n",
    "\n",
    "include(\"jl/omega.jl\")\n",
    "include(\"jl/HSBM.jl\")\n",
    "include(\"jl/hypergraph_louvain.jl\")\n",
    "include(\"jl/inference.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so I think the way this works is that `myfunc` is going to supply the update in the gradient by modifying it in place. This seems very smart -- each function call updates the gradient. So, what we would need to do evaluate the relevant sums and cut terms, then follow this pattern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ω (generic function with 1 method)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters\n",
    "\n",
    "n = 100\n",
    "Z = rand(1:10, n)\n",
    "ϑ = dropdims(ones(1,n) + rand(1,n), dims = 1)\n",
    "\n",
    "# defining group intensity function Ω\n",
    "μ = mean(ϑ)\n",
    "\n",
    "ω(p,α) = maximum(1.0*p).^α[1] / (sum((1.0*p).^α[1])*α[2])\n",
    "\n",
    "α0 = [100.0, 1000]\n",
    "\n",
    "kmax = 3\n",
    "\n",
    "Ω = buildΩ(ω, α0, kmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hypergraph\n",
       "  N: Array{Int64}((100,)) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n",
       "  E: Dict{Int64,Dict}\n",
       "  D: Array{Int64}((100,)) [51, 70, 63, 62, 90, 71, 42, 39, 66, 49  …  68, 60, 60, 51, 52, 84, 63, 62, 56, 48]\n"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = sampleSBM(Z, ϑ, Ω; α=α0, kmax=kmax, kmin = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "obj (generic function with 1 method)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function obj(x)\n",
    "    \"\"\"\n",
    "    objective for optimization. Look into gradients later. \n",
    "    \"\"\"\n",
    "    Q = modularity(H::hypergraph, Z::Array{Int64,1}, Ω; α=x, bigInt=true)\n",
    "#     println(Float64(Q))\n",
    "    return(Float64(-Q))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 6.823825797767675\n",
       " 5.654428282239759e7"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = optimize(obj, 0, [10.0, 1000.0],\n",
    "    NelderMead(),\n",
    "    Optim.Options(f_tol = 1e-10,\n",
    "        iterations = 1000,\n",
    "        show_trace=false))\n",
    "α̂ = Optim.minimizer(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38966.26143714044"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Optim.minimum(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10639.04564657328"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# true\n",
    "logLikelihood(H, Z, Ω, ϑ; α=α0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-Inf"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before estimating α\n",
    "logLikelihood(H, Z, Ω, 1.0*H.D; α=α0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10642.300740435123"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after estimating α\n",
    "logLikelihood(H, Z, Ω, 1.0*H.D; α=α̂)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Louvain Iteration 1\n",
      "No nodes moved clusters\n",
      "-39236.28444138926\n",
      "Louvain Iteration 1\n",
      "Louvain Iteration 2\n",
      "Louvain Iteration 3\n",
      "Louvain Iteration 4\n",
      "Louvain Iteration 5\n",
      "-39012.77153062707\n",
      "Louvain Iteration 1\n",
      "Louvain Iteration 2\n",
      "Louvain Iteration 3\n",
      "Louvain Iteration 4\n",
      "Louvain Iteration 5\n",
      "Louvain Iteration 6\n",
      "Louvain Iteration 7\n",
      "Louvain Iteration 8\n",
      "Louvain Iteration 9\n",
      "Louvain Iteration 10\n",
      "-39000.52400653719\n",
      "Louvain Iteration 1\n",
      "Louvain Iteration 2\n",
      "Louvain Iteration 3\n",
      "Louvain Iteration 4\n",
      "Louvain Iteration 5\n",
      "Louvain Iteration 6\n",
      "Louvain Iteration 7\n",
      "Louvain Iteration 8\n",
      "Louvain Iteration 9\n",
      "Louvain Iteration 10\n",
      "-885828.5158337515\n",
      "Louvain Iteration 1\n",
      "Louvain Iteration 2\n",
      "Louvain Iteration 3\n",
      "-39350.52444521978"
     ]
    }
   ],
   "source": [
    "α̂ = α0\n",
    "Ẑ = Z\n",
    "for i =1:5\n",
    "    Z_prev = Ẑ\n",
    "    Ẑ = HyperLouvain(H,kmax,Ω;α=α̂)\n",
    "#     println(Z_prev==Ẑ)\n",
    "    \n",
    "    function obj(x)\n",
    "        \"\"\"\n",
    "        objective for optimization. Look into gradients later. \n",
    "        \"\"\"\n",
    "        Q = modularity(H, Ẑ, Ω; α=x, bigInt=true)\n",
    "        return(Float64(-Q))\n",
    "    end\n",
    "    \n",
    "    res = optimize(obj, 0, [10.0, 100.0],\n",
    "            NelderMead(),\n",
    "            Optim.Options(f_tol = 1e-10,\n",
    "                iterations = 1000,\n",
    "                show_trace=false))\n",
    "    print(-Optim.minimum(res))\n",
    "    α_prev = α̂\n",
    "    α̂ = Optim.minimizer(res) \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 0.28100945132157384\n",
       " 5.8037980560648486e7"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "α̂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(unique(Ẑ)) # number of clusters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.2",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
